# Оптимизация перемножения матриц

Попытка оптимизировать алгоритм, используя многопоточность и инструменты от Intel. В проекте содержатся несколько проектов, в каждом из которых решается какая-либо проблема оптимизации.

## Для сборки потребуется

Компиляторы MSVC и Intel, а так же OpenMP и поддержка стандарта C++17. 

### Тесты проводились на:
```
Windows 10 x64
Visual Studio 2017
Сборка Release x64
Оптимизирующий компилятор Microsoft (R) C/C++ версии 19.16.27024.1 для x64
Intel(R) C++ Intel(R) 64 Compiler for applications running on Intel(R) 64, Version 19.0.1.144 Build 20181018

Процессор:
  Intel(R) Core(TM) i7-4700HQ CPU @ 2.40GHz
  Максимальная скорость:  2,40 ГГц
  Сокетов:  1
  Ядра:  4
  Логических процессоров:  8
  Виртуализация:  Отключено
  Поддержка Hyper-V:  Да
  Кэш L1:  256 КБ
  Кэш L2:  1,0 МБ
  Кэш L3:  6,0 МБ
```
## Начнем

Обусловимся перемножать квадратные матрицы размера 2^n.

Простой алгоритм перемножает строку матрицы A на столбец матрицы B и суммирует в ячейку матрицы C. 

```
2048, Normal: 83.8924 s.
```

### Performance problem #1

Очевидная проблема простого подхода – кэш промахи. Получив значение матрицы B, процессор prefetch (подгружает) значения поблизости в кэш. Но т.к. умножение на эту матрицу производится по столбцу, процессор не использует prefetched значения (если, конечно, вся матрица не уберется в L1 кэш). Следовательно получаем cache miss.

### Solution #1

Для увеличения локальности данных можно транспонировать матрицу B и производить умножение строка на строку. 

```
2048, Normal Transposed: 9.49514 s.
```
Такой подход сразу дает огромный прирост в скорости в ~10 раз.

### Performance problem #2

Хоть мы и быстро читаем строки матрицы B, мы это делаем N раз. Разумно загрузить данные единожды, полностью их использовать и больше к ним не возвращаться.

### Solution #2

Реализуем блочный алгоритм. Матрицы A, B и C (NxN) делятся на подматрицы. Размер одного блока выберем таким образом, чтобы 3 матрицы N*N типа double умещались в L1 кэше (256Кб). 

n = sqrt(256 * 1024 / (3 * 8)) = 104.51. 

Т.к. мы обусловились брать матрицы размера 2^n и размер матрицы должен делиться на размер подматрицы нацело, то выберем блок равным 64. 

```
2048, Tiled: 8.12238 s.
2048, Tiled Transposed: 8.06461 s.
```
Прирост в скорости ~17%

### Performance problem #3

Программа выполняется в одном потоке, что для современного процессора лишь небольшая часть его вычислительной мощности.

### Solution #3

Утилизируем оставшиеся вычислительные ядра процессора. Для этого воспользуемся OpenMP. Добавим *#pragma omp parallel for* перед внешним циклом.

```
2048, Tiled Parallel: 1.83215 s.
2048, Tiled Parallel Transposed: 1.46838 s.
```
Прирост в скорости в ~5 раз.

### Performance problem??? #4 

Нашел на youtube следующий плейлист [Cache-optimized matrix multiplication](https://www.youtube.com/watch?v=QYpH-847z0E&list=PLB_aWiiTt1af-dICxt6E7pNJWrfcqHE2g). Там предлагается алгоритм двойного разбиения на блоки. Блок делится на 4 подблок, которые так же перемножаются. Полагаясь на видео [Matrix multiplication: tiled implementation with visible L1 cache](https://www.youtube.com/watch?v=aU1zsFk36l0&index=4&list=PLB_aWiiTt1af-dICxt6E7pNJWrfcqHE2g) и [Matrix multiplication: 2-level tiled implementation](https://www.youtube.com/watch?v=3XfHL6nlB08&index=5&list=PLB_aWiiTt1af-dICxt6E7pNJWrfcqHE2g), во втором варианте меньше промахов в L2 кэше. 

### Solution #4

Реализуем двухуровневый блочный алгоритм. Подблоки будут размера равным половины размеры блока.

```
2048, Double Tiled Parallel: 2.0025 s.
2048, Double Tiled Parallel Transposed: 1.8819 s.
```

На первый взгляд производительность ниже, чем у предыдущегго решения. Попробуем увеличить размер начального блока в 2 раза (128x128).

```
2048, Double Tiled Parallel: 1.77569 s.
2048, Double Tiled Parallel Transposed: 1.55421 s.
```
Результаты схожи с предыдущим решением.

### Performance problem #5

На этот раз я воспользовался *Intel Adviser*. Компилятору недостаточно информации, чтобы убедиться, что цикл можно векторизировать. 

### Solution #5

Компилятор MSVC позволяет узнать информацию о том, какие циклы были векторизированы, а какие не были и почему. Компилируем программу с параметром */Qvec-report:2*.

```
info C5002: цикл не векторизирован по следующей причине: "1200"
```

C сайта MSDN узнаём, что причина «1200»:

*Цикл содержит связанные с циклом зависимости данных, исключающие векторизацию. Различные итерации цикла взаимодействуют между собой таким образом, что векторизация цикла приведет к получению ошибочных результатов; автоматический векторизатор не может удостовериться в отсутствии таких зависимостей данных.*

Чтобы решить эту проблему рекомендуется переписать код. Вероятно класс tile мешает компилятору. Так же в интернетах была рекомендация – суммировать в локальную переменную. Я так и сделал. Но мне так и не удалось уговорить компилятор векторизировать цикл. В результате было решено использовать компилятор *Intel 19.0*. после этого *Intel Adviser* дал более информативное сообщение.

```
Percise FP model implied by the command line or a directive prevents vectorization. Consider using fast FP model. 
```

Добавим директиву /fp:fast в командную строку. Intel Adviser показал, что векторизация цикла удалась.

```
2048, Double Tiled Parallel Vectorized: 1.94252 s.
2048, Double Tiled Parallel Vectorized Transposed: 1.0584 s.
```
Прирост в скорости после векторизации ~40%

### Performance (recomendation) #6

Intel Adviser рекомендует использовать директиву */Qoverride-limits* и включить поддержку AVX2 инструкции */arch:AVX2*.

```
2048, Double Tiled Parallel Vectorized Intel: 2.4676 s.
2048, Double Tiled Parallel Vectorized Intel Transposed: 0.846375 s.
```
 
 ## Тестирование алгоритмов
 
 Лучшие результаты показывают блочный и двойной блочный алгоритм, оба использующие транспонированную матрицу B. Следует лишь подобрать оптимальный размер блока. 
 
 Для блочного (64x64), для двойного блочного (128x128)
 ``` 
2048, Tiled Parallel Vectorized Intel: 1.79315 s.
2048, Tiled Parallel Vectorized Intel Transposed: 0.505744 s.

2048, Double Tiled Parallel Vectorized Intel: 1.73502 s.
2048, Double Tiled Parallel Vectorized Intel Transposed: 0.485537 s.
```
Блочный алгоритм с (64x64) и двойной блочный алгоритм (128x128) показывают похожие результаты. Ускорение по сравнению с обычным алгоритмом в ~150 раз.